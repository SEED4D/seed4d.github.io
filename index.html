<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="Few-view Reconstruction of Large-Scale Scenes from Outward-Looking Cameras">
  <meta name="keywords" content="Scene Representation, Few-View Reconstruction, 3D Reconstruction, Autonomous Vehicles">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SEED4D</title>

  <!-- Global site tag (gtag.js) - Google Analytics
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script> -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="apple-touch-icon" sizes="57x57" href="/static/images/icon/apple-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="60x60" href="/static/images/icon/apple-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/static/images/icon/apple-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="/static/images/icon/apple-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="/static/images/icon/apple-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="/static/images/icon/apple-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="/static/images/icon/apple-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/static/images/icon/apple-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/static/images/icon/apple-icon-180x180.png">
  <link rel="icon" type="image/png" sizes="192x192" href="/android-icon-192x192.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/static/images/icon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="96x96" href="/static/images/icon/favicon-96x96.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/static/images/icon/favicon-16x16.png">
  <link rel="manifest" href="/static/images/icon/manifest.json">
  <meta name="msapplication-TileColor" content="#ffffff">
  <meta name="msapplication-TileImage" content="/ms-icon-144x144.png">
  <meta name="theme-color" content="#ffffff">
  <script src="./static/js/video-comparison.js"></script>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>



  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h2 class="title is-1 publication-title">
              SEED4D: A Synthetic Ego-Exo Dynamic 4D Data Generator, Driving Dataset and Benchmark
            </h2>
            <h2 class="subtitle is-3">WACV 2025</h2>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://twitter.com/marten_marius">Marius Kaestingschaefer</a><sup>1,2</sup>,</span>
                <a href="https://github.com/tgieruc">Théo Gieruc</a><sup>1</sup>,</span>
                <a href="https://www.linkedin.com/in/dr-ing-sebastian-bernhard-79a763205/"">Sebastian Bernhard</a><sup>1</sup>,</span>
                <a href=""><br></a><sup></sup></span>
                <a href="https://sites.google.com/view/djcampbell">Dylan Campbell</a><sup>3</sup></span>
                <a href="https://eldar.insafutdinov.com/">Eldar Insafutdinov</a><sup>4</sup></span>
                <a href="https://www.linkedin.com/in/eyvaz-najafli-43407618b/">Eyvaz Najafli </a><sup>1,5</sup></span>
                <a href="https://lmb.informatik.uni-freiburg.de/people/brox/index.en.html">Thomas Brox </a><sup>2</sup></span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Continental AG,</span>
              <span class="author-block"><sup>2</sup>University of Freiburg,</span>
              <span class="author-block"><sup>3</sup>Australian National University,</span>
              <a href=""><br></a><sup></sup></span>
              <span class="author-block"><sup>4</sup>University of Oxford,</span>
              <span class="author-block"><sup>5</sup>University of Tübingen,</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
               <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2412.00730"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2412.00730"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
                <!-- Video Link. -->
                <span class="link-block">
                  <a href="https://www.youtube.com/@seed4d"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-youtube"></i>
                    </span>
                    <span>Videos</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/continental/seed4D"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- Dataset Link. -->
                  <span class="link-block">
                    <a href="https://github.com/coming-soon"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                          <i class="far fa-images"></i>
                      </span>
                      <span>Data</span>
                    </a>
                  </span>
                </div>
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>

  </section>





  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
               <strong> SEED4D is a large-scale synthetic multi-view dynamic 4D driving dataset, data generator and benchmarks.</strong> 
              Models for egocentric 3D and 4D reconstruction, including few-shot interpolation and extrapolation settings, 
              can benefit from having images from exocentric viewpoints as supervision signals. No existing dataset provides 
              the necessary mixture of complex, dynamic, and multi-view data. To facilitate the development of 3D and 4D reconstruction 
              methods in the autonomous driving context, we propose a <b>Synthetic Ego--Exo Dynamic 4D (SEED4D)</b>   dataset. SEED4D encompasses 
              two large-scale multi-view synthetic urban scene datasets. Our static (3D) dataset encompasses 212K inward- and outward-facing 
              vehicle images from 2K scenes, while our dynamic (4D) dataset contains 16.8M images from 10K trajectories, each sampled at 100 
              points in time with egocentric images, exocentric images, and LiDAR data. We additionally present a customizable, easy-to-use 
              data generator for spatio-temporal multi-view data creation. Our open-source data generator allows the creation of synthetic 
              data for camera setups commonly used in the NuScenes, KITTI360, and Waymo datasets.
            </p>
          </div>
        </div>
      </div>
      <div class="column is-full-width">
        <img src="./static/images/paper_overview.PNG" alt="Image description"
          style="width: 100%; height: auto;">
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Datasets</h2>
          <div class="content has-text-justified">
            <p>
              <strong> Static Ego-Exo Dataset.</strong> We introduce a novel dataset for few-view image reconstruction tasks in an autonomous driving setting. 
              Our dataset contains 2002 single-timestep complex outdoor driving scenes, each offering six plus one outward-facing vehicle images and 100 images 
              from exocentric viewpoints on a bounding sphere for supervision. Only a single vehicle in the scene is equipped with this setup. We define ego views 
              to be 900 x 1600 to match the NuScenes dataset and the surround vehicle exo views to be 600 x 800.
            </p>
            <p>
              <strong> Dynamic Ego-Exo Dataset.</strong> Our temporal dataset consists of 10.5K driving trajectories well-suited for 4D forecasting, 
              4D reconstruction, or video prediction tasks. Each trajectory is 100 steps long, corresponding to a driving length of 10 seconds. 
              The 10.5k trajectories come from a total of 498 scenes across all towns. In each scene, the number of vehicles is set to $21$, 
              all equipped with six plus one outward-facing vehicle camera and ten inward-facing surround vehicle exocentric images. 
              The ego views have size 128 x 256 and the exo views are set to 98 x 128.
            </p>
            <p>
              The static and the dynamic ego--exo view datasets are visualized in the Figure below. 
              They differ mainly in image resolution and trajectory length and have complementary strengths.
               The static ego--exo dataset contains 12k egocentric views and 200k exocentric views. 
               The dynamic ego--exo dataset contains 6.3M egocentric views and 10.5M exocentric views.
            </p>
          </div>
        </div>
      </div>
      <div class="column is-full-width">
        <img src="./static/images/overview_datasets.PNG" alt="Image description"
          style="width: 100%; height: auto;">
      </div>
      <!--/ Concurrent Work. -->
    </div>
    </div>
  </section>

  <section class="section">
  <div class="container is-max-desktop">
  <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
        <h2 class="title is-3">Benchmark Results</h2>
        <div class="content has-text-justified">
          <p>
            <strong> Multi-view Novel View Synthesis.</strong> We evaluate how well existing methods can reconstruct the scene given many spherical views. 
            We divide the 100 spherical views into training and test data using an 80/20 split.
          </p>
          <p>
            <strong> Monocular Metric Depth Estimation.</strong> Since our dataset contains ground truth depth maps we evaluated two recent monocular metric depth estimation methods.
             The methods we tested without further fine-tuning them on our data.
          </p>
          <p>
            <strong> Single-shot Few-Image Scene Reconstruction.</strong> For performing few-image-to-3D reconstruction, we deviate from many of the existing comparisons by 
            targeting an automotive use-case and, hence evaluated the performance of methods on egocentric outward-facing views while supervising resulting novel
             views with  360° exocentrical spherical views.
         </p>
            <table class="styled-table">
                <thead>
                    <tr>
                        <th>Evaluation</th>
                        <th>Method</th>
                        <th>PSNR <span style="vertical-align: super;">↑</span></th>
                        <th>SSIM <span style="vertical-align: super;">↑</span></th>
                        <th>LPIPS <span style="vertical-align: super;">↓</span></th>
                        <th>RMSE (m) <span style="vertical-align: super;">↓</span></th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>Multi-view</td>
                        <td>SplatFacto [<a href="https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/">3</a>,<a href="https://github.com/nerfstudio-project/gsplat">4</a>]</td>
                        <td>24.458</td>
                        <td>0.806</td>
                        <td>0.210</td>
                        <td>-</td>
                    </tr>
                    <tr>
                      <td>Multi-view</td>
                        <td>NeRFacto [<a href="https://docs.nerf.studio/nerfology/methods/nerfacto.html">5</a>]</td>
                        <td>24.936</td>
                        <td>0.804</td>
                        <td>0.227</td>
                        <td>-</td>
                    </tr>
                    <tr>
                        <td>Multi-view</td>
                        <td>K-Planes [<a href="https://sarafridov.github.io/K-Planes/">1</a>,<a href="https://github.com/Giodiro/kplanes_nerfstudio">2</a>]</td>
                        <td>25.744</td>
                        <td>0.816</td>
                        <td>0.239</td>
                        <td>-</td>
                    </tr>
                    <tr>
                        <td>Monocular Depth</td>
                        <td>ZoeDepth [<a href="https://github.com/isl-org/ZoeDepth">7</a>]</td>
                        <td>-</td>
                        <td>-</td>
                        <td>-</td>
                        <td>12.352</td>
                    </tr>
                    <tr>
                        <td>Monocular Depth</td> 
                        <td>Metric3D [<a href="https://jugghm.github.io/Metric3Dv2/">6</a>]</td>
                        <td>-</td>
                        <td>-</td>
                        <td>-</td>
                        <td>7.668</td>
                    </tr>
                    <tr>
                        <td>Few-view</td>
                        <td>K-Planes [<a href="https://sarafridov.github.io/K-Planes/">1</a>,<a href="https://github.com/Giodiro/kplanes_nerfstudio">2</a>]</td>
                        <td>11.356</td>
                        <td>0.463</td>
                        <td>0.633</td>
                        <td>-</td>
                    </tr>
                    <tr>
                        <td>Few-view</td>
                        <td>SplatFacto [<a href="https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/">3</a>,<a href="https://github.com/nerfstudio-project/gsplat">4</a>]</td>
                        <td>11.607</td>
                        <td>0.486</td>
                        <td>0.658</td>
                        <td>-</td>
                    </tr>
                    <tr>
                        <td>Few-view</td>
                        <td>NeRFacto [<a href="https://docs.nerf.studio/nerfology/methods/nerfacto.html">5</a>]</td>
                        <td>10.943</td>
                        <td>0.298</td>
                        <td>0.791</td>
                        <td>-</td>
                    </tr>
                    <tr>
                      <td>Few-view</td>
                        <td>PixelNeRF [<a href="https://alexyu.net/pixelnerf/">8</a>]</td>
                        <td>14.500</td>
                        <td>0.550</td>
                        <td>0.652</td>
                        <td>19.235</td>
                    </tr>
                    <tr>
                      <td>Few-view</td>
                        <td>SplatterImage [<a href="https://szymanowiczs.github.io/splatter-image">9</a>]</td>
                        <td>17.791</td>
                        <td>0.580</td>
                        <td>0.568</td>
                        <td>11.049</td>
                    </tr>
                    <tr>
                      <td>Few-view</td>
                        <td>6Img-to-3D [<a href="https://6img-to-3d.github.io/">10</a>]</td>
                        <td>18.682</td>
                        <td>0.726</td>
                        <td>0.451</td>
                        <td>6.232</td>
                    </tr>
                </tbody>
            </table>
            <p> 

            </p>
            <p>
              We welcome submissions. Please reach out to us via <a href="mailto:marius.kaestingschaefer@continental.com?body=Hi%20Marius,&subject=SEED4D%20Benchmark%20Submission">email</a>!
            </p>
        </div>
    </div>
</div>
</div>
</section>


  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Data Generator</h2>
          <div class="content has-text-justified">
            <p>
              Both datasets contained in this paper are generated using our <strong> data generator.</strong>. 
              The data generator provides an easy-to-use front-end for the  <a href="https://carla.org//">CARLA Simulator</a>. 
              With our data generator, one can easily define parameters such as the town, the vehicle's initial position, 
              the weather, the number of traffic participants, the number and kinds of sensors, and their position (both ego and exo-views).
            </p>
            <p>
              Several different <strong> sensor readings</strong> are available within our dataset:
            </p>
          </div>
        </div>
      </div>

      <div class="columns is-centered  has-text-centered">
        <div class="column is-full-width">
          <img src="./static/images/sensors.png" alt="Image description"
            style="width: 100%; height: auto; float: center;">
        </div>
      </div>
      <div class="column has-text-centered">
        <div class="column is four-fifths">
          <span class="dnerf">The dataset provides RGB, depth maps, semantic and instance segmentation for each
            image.<br>
            Furthermore, the 3D bounding boxes of each vehicle in the scene is also available</span>
        </div>
      </div>


      <div class="columns is-centered">
        <!-- Visual Effects. -->
        <div class="column">
          <div class="content">
            <div class="video-compare-container">
              <video class="video" id="dataset1" loop autoplay muted src="./static/videos/dataset/inst_depth.mp4"
                onplay="resizeAndPlay(this)"></video>
              <canvas height="0" class="videoMerge" id="dataset1Merge"></canvas>
            </div>
          </div>
        </div>
        <!--/ Visual Effects. -->

        <!-- Matting. -->
        <div class="column">
          <div class="columns is-centered">
            <div class="column content">
              <div class="video-compare-container">
                <video class="video" id="dataset2" loop autoplay muted src="./static/videos/dataset/bbox_sem.mp4"
                  onplay="resizeAndPlay(this)"></video>
                <canvas height="0" class="videoMerge" id="dataset2Merge"></canvas>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>



  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-full-width">
          <div class="content has-text-centered">
            <h2 class="title is-3">Towns</a></h2>
          </div>
          <p>
            The generated data come from Towns 1 to 7 and 10HD.
             Towns 1, 3 to 7, and 10HD are used for training and we left all 100 scenes from Town 2 for testing.
          </p>
        <div class="columns is-centered has-text-justified">
          <div class="column is-four-fifths">
            <table class="styled-table">
              <thead>
                <tr>
                  <th>Town</th>
                  <th>Number of Scenes</th>
                  <th>Split</th>
                  <th>Description</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>Town01</td>
                  <td>255</td>
                  <td>Train</td>
                  <td>A small, simple town with a river and several bridges.</td>
                </tr>
                <tr>
                  <td>Town03</td>
                  <td>265</td>
                  <td>Train</td>
                  <td>A larger, urban map with a roundabout and large junctions.</td>
                </tr>
                <tr>
                  <td>Town04</td>
                  <td>372</td>
                  <td>Train</td>
                  <td>A small town embedded in the mountains with a special "figure of 8" infinite highway.</td>
                </tr>
                <tr>
                  <td>Town05</td>
                  <td>302</td>
                  <td>Train</td>
                  <td>Squared-grid town with cross junctions and a bridge. It has multiple lanes per direction. Useful
                    to
                    perform lane changes.</td>
                </tr>
                <tr>
                  <td>Town06</td>
                  <td>436</td>
                  <td>Train</td>
                  <td>Long many lane highways with many highway entrances and exits. It also has a Michigan left.</td>
                </tr>
                <tr>
                  <td>Town07</td>
                  <td>116</td>
                  <td>Train</td>
                  <td>A rural environment with narrow roads, corn, barns and hardly any traffic lights.</td>
                </tr>
                <tr>
                  <td>Town10</td>
                  <td>155</td>
                  <td>Train</td>
                  <td>A downtown urban environment with skyscrapers, residential buildings and an ocean promenade.
                  </td>
                </tr>
                <tr>
                  <td>Town02</td>
                  <td>101</td>
                  <td>Val</td>
                  <td>A small simple town with a mixture of residential and commercial buildings.</td>
                </tr>
              </tbody>
            </table>
          </div>
        </div>
      </div>
  </section>

  <section>
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is four-fifths">
          <table class="town-table">
            <colgroup>
              <col width="1.5cm">
              <col>
              <col>
              <col>
              <col>
              <col>
              <col>
            </colgroup>
            <thead>
              <tr>
                <th>Town</th>
                <th colspan="3" style="text-align: center;">Input</th>
                <th colspan="3" style="text-align: center;">Supervision</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td class="rotation-cell" rowspan="2">Town 1</td>
                <td><img src="figures/t1/n/2_rgb.png" alt="input image" class="input-image"></td>
                <td><img src="figures/t1/n/0_rgb.png" alt="input image" class="input-image"></td>
                <td><img src="figures/t1/n/1_rgb.png" alt="input image" class="input-image"></td>
                <td><img src="figures/t1/s/1_rgb.png" alt="supervision image" class="supervision-image"></td>
                <td><img src="figures/t1/s/13_rgb.png" alt="supervision image" class="supervision-image"></td>
                <td><img src="figures/t1/s/15_rgb.png" alt="supervision image" class="supervision-image"></td>
              </tr>
              <tr class="border">
                <td><img src="figures/t1/n/4_rgb.png" alt="input image" class="input-image"></td>
                <td><img src="figures/t1/n/3_rgb.png" alt="input image" class="input-image"></td>
                <td><img src="figures/t1/n/5_rgb.png" alt="input image" class="input-image"></td>
                <td><img src="figures/t1/s/21_rgb.png" alt="supervision image" class="supervision-image"></td>
                <td><img src="figures/t1/s/3_rgb.png" alt="supervision image" class="supervision-image"></td>
                <td><img src="figures/t1/s/5_rgb.png" alt="supervision image" class="supervision-image"></td>
              </tr>
              <tr>
                <td class="rotation-cell" rowspan="2">Town 2</td>
                <td><img src="figures/t2/n/2_rgb.png" alt="input image" class="input-image"></td>
                <td><img src="figures/t2/n/0_rgb.png" alt="input image" class="input-image"></td>
                <td><img src="figures/t2/n/1_rgb.png" alt="input image" class="input-image"></td>
                <td><img src="figures/t2/s/17_rgb.png" alt="supervision image" class="supervision-image"></td>
                <td><img src="figures/t2/s/32_rgb.png" alt="supervision image" class="supervision-image"></td>
                <td><img src="figures/t2/s/77_rgb.png" alt="supervision image" class="supervision-image"></td>
              </tr>
              <tr class="border">
                <td><img src="figures/t2/n/4_rgb.png" alt="input image" class="input-image"></td>
                <td><img src="figures/t2/n/3_rgb.png" alt="input image" class="input-image"></td>
                <td><img src="figures/t2/n/5_rgb.png" alt="input image" class="input-image"></td>
                <td><img src="figures/t2/s/81_rgb.png" alt="supervision image" class="supervision-image"></td>
                <td><img src="figures/t2/s/84_rgb.png" alt="supervision image" class="supervision-image"></td>
                <td><img src="figures/t2/s/99_rgb.png" alt="supervision image" class="supervision-image"></td>
              </tr>
              <tr>
                <td class="rotation-cell" rowspan="2">Town 3</td>
                <td><img src="figures/t3/n/2_rgb.png" alt="input image" class="input-image"></td>
                <td><img src="figures/t3/n/0_rgb.png" alt="input image" class="input-image"></td>
                <td><img src="figures/t3/n/1_rgb.png" alt="input image" class="input-image"></td>
                <td><img src="figures/t3/s/17_rgb.png" alt="supervision image" class="supervision-image"></td>
                <td><img src="figures/t3/s/32_rgb.png" alt="supervision image" class="supervision-image"></td>
                <td><img src="figures/t3/s/77_rgb.png" alt="supervision image" class="supervision-image"></td>
              </tr>
              <tr class="border">
                <td><img src="figures/t3/n/4_rgb.png" alt="input image" class="input-image"></td>
                <td><img src="figures/t3/n/3_rgb.png" alt="input image" class="input-image"></td>
                <td><img src="figures/t3/n/5_rgb.png" alt="input image" class="input-image"></td>
                <td><img src="figures/t3/s/81_rgb.png" alt="supervision image" class="supervision-image"></td>
                <td><img src="figures/t3/s/84_rgb.png" alt="supervision image" class="supervision-image"></td>
                <td><img src="figures/t3/s/99_rgb.png" alt="supervision image" class="supervision-image"></td>
              </tr>
              <tr>
                <td class="rotation-cell" rowspan="2">Town 4</td>
                <td><img src="figures/t4/n/2_rgb.png" alt="input image" class="input-image"></td>
                <td><img src="figures/t4/n/0_rgb.png" alt="input image" class="input-image"></td>
                <td><img src="figures/t4/n/1_rgb.png" alt="input image" class="input-image"></td>
                <td><img src="figures/t4/s/12_rgb.png" alt="supervision image" class="supervision-image"></td>
                <td><img src="figures/t4/s/20_rgb.png" alt="supervision image" class="supervision-image"></td>
                <td><img src="figures/t4/s/3_rgb.png" alt="supervision image" class="supervision-image"></td>
              </tr>
              <tr class="border">
                <td><img src="figures/t4/n/4_rgb.png" alt="input image" class="input-image"></td>
                <td><img src="figures/t4/n/3_rgb.png" alt="input image" class="input-image"></td>
                <td><img src="figures/t4/n/5_rgb.png" alt="input image" class="input-image"></td>
                <td><img src="figures/t4/s/43_rgb.png" alt="supervision image" class="supervision-image"></td>
                <td><img src="figures/t4/s/5_rgb.png" alt="supervision image" class="supervision-image"></td>
                <td><img src="figures/t4/s/95_rgb.png" alt="supervision image" class="supervision-image"></td>
              </tr>
              <tr>
                <td class="rotation-cell" rowspan="2">Town 5</td>
                <td><img src="figures/t5/n/2_rgb.png" alt="input image" class="input-image"></td>
                <td><img src="figures/t5/n/0_rgb.png" alt="input image" class="input-image"></td>
                <td><img src="figures/t5/n/1_rgb.png" alt="input image" class="input-image"></td>
                <td><img src="figures/t5/s/12_rgb.png" alt="supervision image" class="supervision-image"></td>
                <td><img src="figures/t5/s/14_rgb.png" alt="supervision image" class="supervision-image"></td>
                <td><img src="figures/t5/s/45_rgb.png" alt="supervision image" class="supervision-image"></td>
              </tr>
              <tr class="border">
                <td><img src="figures/t5/n/4_rgb.png" alt="input image" class="input-image"></td>
                <td><img src="figures/t5/n/3_rgb.png" alt="input image" class="input-image"></td>
                <td><img src="figures/t5/n/5_rgb.png" alt="input image" class="input-image"></td>
                <td><img src="figures/t5/s/49_rgb.png" alt="supervision image" class="supervision-image"></td>
                <td><img src="figures/t5/s/52_rgb.png" alt="supervision image" class="supervision-image"></td>
                <td><img src="figures/t5/s/7_rgb.png" alt="supervision image" class="supervision-image"></td>
              </tr>
              <tr>
                <td class="rotation-cell" rowspan="2">Town 6</td>
                <td><img src="figures/t6/n/2_rgb.png" alt="input image" class="input-image"></td>
                <td><img src="figures/t6/n/0_rgb.png" alt="input image" class="input-image"></td>
                <td><img src="figures/t6/n/1_rgb.png" alt="input image" class="input-image"></td>
                <td><img src="figures/t6/s/30_rgb.png" alt="supervision image" class="supervision-image"></td>
                <td><img src="figures/t6/s/55_rgb.png" alt="supervision image" class="supervision-image"></td>
                <td><img src="figures/t6/s/56_rgb.png" alt="supervision image" class="supervision-image"></td>
              </tr>
              <tr class="border">
                <td><img src="figures/t6/n/4_rgb.png" alt="input image" class="input-image"></td>
                <td><img src="figures/t6/n/3_rgb.png" alt="input image" class="input-image"></td>
                <td><img src="figures/t6/n/5_rgb.png" alt="input image" class="input-image"></td>
                <td><img src="figures/t6/s/30_rgb.png" alt="supervision image" class="supervision-image"></td>
                <td><img src="figures/t6/s/55_rgb.png" alt="supervision image" class="supervision-image"></td>
                <td><img src="figures/t6/s/56_rgb.png" alt="supervision image" class="supervision-image"></td>
              </tr>
              <tr>
                <td class="rotation-cell" rowspan="2">Town 7</td>
                <td><img src="figures/t7/n/2_rgb.png" alt="input image" class="input-image"></td>
                <td><img src="figures/t7/n/0_rgb.png" alt="input image" class="input-image"></td>
                <td><img src="figures/t7/n/1_rgb.png" alt="input image" class="input-image"></td>
                <td><img src="figures/t7/s/16_rgb.png" alt="supervision image" class="supervision-image"></td>
                <td><img src="figures/t7/s/21_rgb.png" alt="supervision image" class="supervision-image"></td>
                <td><img src="figures/t7/s/31_rgb.png" alt="supervision image" class="supervision-image"></td>
              </tr>
              <tr class="border">
                <td><img src="figures/t7/n/4_rgb.png" alt="input image" class="input-image"></td>
                <td><img src="figures/t7/n/3_rgb.png" alt="input image" class="input-image"></td>
                <td><img src="figures/t7/n/5_rgb.png" alt="input image" class="input-image"></td>
                <td><img src="figures/t7/s/73_rgb.png" alt="supervision image" class="supervision-image"></td>
                <td><img src="figures/t7/s/74_rgb.png" alt="supervision image" class="supervision-image"></td>
                <td><img src="figures/t7/s/77_rgb.png" alt="supervision image" class="supervision-image"></td>
              </tr>
            </tbody>
          </table>


        </div>
      </div>
  </section>

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{kaestingschaefer2024seed4dsyntheticegoexodynamic,
      title={SEED4D: A Synthetic Ego--Exo Dynamic 4D Data Generator, Driving Dataset and Benchmark}, 
      author={Marius Kästingschäfer and Théo Gieruc and Sebastian Bernhard and Dylan Campbell and Eldar Insafutdinov and Eyvaz Najafli and Thomas Brox},
      year={2024},
      eprint={2412.00730},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2412.00730},
      journal      = {arXiv preprint},
      volume     = {arXiv:2412.00730},
}</code></pre>
    </div>
  </section>

  
  <section class="section" id="Ack">
    <div class="container is-max-desktop content">
      <h2 class="title">Acknowledgement</h2>
      We thank <a
      href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> for the website template.
    </div>
  </section>

</body>

</html>
